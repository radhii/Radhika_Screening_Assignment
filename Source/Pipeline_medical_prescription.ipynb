{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22965f36-af3e-4788-badc-0dad97089f84",
   "metadata": {},
   "source": [
    "pip install ollama-ocr pandas openpyxl langchain_community spacy\n",
    "python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a154fd22-58d3-4874-a90e-abf031417bd1",
   "metadata": {},
   "source": [
    "ollama serve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131f2c43-fb5a-4fb2-afac-9a6dfb143430",
   "metadata": {},
   "source": [
    "ollama pull llama3.2-vision:11b\n",
    "ollama pull llama2:13b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686a5e39-e38f-49c8-93f9-35794ed09099",
   "metadata": {},
   "source": [
    "Pipeline Medical Prescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c95e4a9-981f-49b0-b844-49f9ea127e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ollama_ocr import OCRProcessor\n",
    "from langchain_community.llms import Ollama\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "# Initialize OCR processor with vision model\n",
    "ocr = OCRProcessor(model_name='llama3.2-vision:11b')\n",
    "\n",
    "# Initialize Llama 13B text model for NLP\n",
    "llama = Ollama(base_url='http://localhost:11434', model='llama2:13b')\n",
    "\n",
    "# Load spaCy for basic NLP preprocessing \n",
    "nlp_spacy = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Directory with prescription images\n",
    "IMAGE_DIR = r'C:\\Users\\yayuk\\medical prescription images'\n",
    "\n",
    "# Output files\n",
    "OCR_OUTPUT_FILE = \"ocr_results.xlsx\"\n",
    "STRUCTURED_OUTPUT_FILE = \"structured_prescriptions.xlsx\"\n",
    "\n",
    "def extract_text_from_images(image_dir):\n",
    "    results = []\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            print(f\"Processing OCR for {filename}...\")\n",
    "            try:\n",
    "                text = ocr.process_image(image_path, format_type=\"text\")\n",
    "                results.append({\"filename\": filename, \"extracted_text\": text})\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {repr(e)}\")\n",
    "                results.append({\"filename\": filename, \"extracted_text\": \"\"})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def clean_text(text):\n",
    "    # Basic cleaning - remove excessive whitespace\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def extract_medicine_dosage(text):\n",
    "    \"\"\"\n",
    "    Use Llama 13B to extract medicines and dosages in a structured format.\n",
    "    We prompt Llama to output data in JSON for easier parsing.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are a medical assistant. Extract the medicines and their dosages from the following prescription text.\n",
    "Return the result as a JSON list of objects with \"medicine\" and \"dosage\" fields.\n",
    "\n",
    "Prescription text:\n",
    "\\\"\\\"\\\"\n",
    "{text}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "JSON output:\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = llama.invoke(prompt)\n",
    "        return response.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during NLP extraction: {repr(e)}\")\n",
    "        return \"[]\"\n",
    "\n",
    "def parse_llama_json_response(response_text):\n",
    "    import json\n",
    "    try:\n",
    "        data = json.loads(response_text)\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "        else:\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"JSON parsing error: {repr(e)}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    # Step 1: OCR extraction\n",
    "    ocr_df = extract_text_from_images(IMAGE_DIR)\n",
    "    ocr_df.to_excel(OCR_OUTPUT_FILE, index=False)\n",
    "    print(f\"OCR results saved to {OCR_OUTPUT_FILE}\")\n",
    "\n",
    "    # Step 2: NLP extraction of medicine and dosage\n",
    "    structured_rows = []\n",
    "    for idx, row in ocr_df.iterrows():\n",
    "        filename = row['filename']\n",
    "        text = clean_text(row['extracted_text'])\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        print(f\"Extracting medicines from {filename}...\")\n",
    "        json_response = extract_medicine_dosage(text)\n",
    "        meds = parse_llama_json_response(json_response)\n",
    "\n",
    "        if not meds:\n",
    "            # No meds found, still record empty row for traceability\n",
    "            structured_rows.append({\n",
    "                \"filename\": filename,\n",
    "                \"medicine\": None,\n",
    "                \"dosage\": None\n",
    "            })\n",
    "        else:\n",
    "            for med in meds:\n",
    "                structured_rows.append({\n",
    "                    \"filename\": filename,\n",
    "                    \"medicine\": med.get(\"medicine\"),\n",
    "                    \"dosage\": med.get(\"dosage\")\n",
    "                })\n",
    "\n",
    "    structured_df = pd.DataFrame(structured_rows)\n",
    "    structured_df.to_excel(STRUCTURED_OUTPUT_FILE, index=False)\n",
    "    print(f\"Structured prescription data saved to {STRUCTURED_OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92901c9-8814-4224-aafd-af9269ed231d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0144224-d601-4b5b-b847-bc276623a617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f6b9b-5764-4519-8c8a-2ae0fd50a34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33541cc6-6897-4aea-8552-8855fb60cda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb439bb-91f0-4601-8e6c-73e9d1bce25f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3e248f-1b69-4e9b-9dca-c47deee898c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c14d33-da15-48c1-aff3-1b48fe164dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
